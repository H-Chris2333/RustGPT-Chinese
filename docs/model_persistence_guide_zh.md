# æ¨¡å‹æŒä¹…åŒ–ä½¿ç”¨æŒ‡å—

æœ¬æ–‡æ¡£è¯´æ˜å¦‚ä½•ä½¿ç”¨ RustGPT-Chinese çš„æ¨¡å‹æŒä¹…åŒ–åŠŸèƒ½ã€‚

## ğŸ“š åŠŸèƒ½æ¦‚è¿°

æ¨¡å‹æŒä¹…åŒ–åŠŸèƒ½æ”¯æŒä¸¤ç§æ ¼å¼:

### 1. äºŒè¿›åˆ¶æ ¼å¼ (.bin) - æ¨èç”¨äºç”Ÿäº§

**ä¼˜ç‚¹:**
- æ–‡ä»¶å°ã€åŠ è½½é€Ÿåº¦å¿«
- ä¿å­˜å®Œæ•´çš„ä¼˜åŒ–å™¨çŠ¶æ€(AdamåŠ¨é‡)
- æ”¯æŒæ–­ç‚¹ç»­è®­

**é€‚ç”¨åœºæ™¯:**
- æ—¥å¸¸è®­ç»ƒcheckpointä¿å­˜
- é•¿æœŸè®­ç»ƒä¸­é—´çŠ¶æ€ä¿å­˜
- ç”Ÿäº§ç¯å¢ƒæ¨¡å‹éƒ¨ç½²

### 2. JSON æ ¼å¼ (.json) - æ¨èç”¨äºè°ƒè¯•

**ä¼˜ç‚¹:**
- äººç±»å¯è¯»,æ–¹ä¾¿æ£€æŸ¥æƒé‡
- è·¨è¯­è¨€å…¼å®¹,å¯ç”¨Pythonè¯»å–
- ä¿å­˜å®Œæ•´çš„ä¼˜åŒ–å™¨çŠ¶æ€
- æ–¹ä¾¿æ‰‹åŠ¨ç¼–è¾‘å’Œåˆ†æ

**é€‚ç”¨åœºæ™¯:**
- è°ƒè¯•è®­ç»ƒè¿‡ç¨‹
- ä¸å…¶ä»–æ¡†æ¶/è¯­è¨€å…±äº«æƒé‡
- ç ”ç©¶å’Œåˆ†ææ¨¡å‹å‚æ•°

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. åŸºæœ¬ä½¿ç”¨

```rust
use llm::{LLM, save_model_binary, load_model_binary};

// åˆ›å»ºæˆ–è®­ç»ƒæ¨¡å‹
let mut llm = LLM::default();

// è®­ç»ƒä»£ç ...
// llm.train(...);

// ä¿å­˜æ¨¡å‹åˆ°äºŒè¿›åˆ¶æ–‡ä»¶
save_model_binary(&llm, "checkpoints/model_epoch_100.bin")?;

// åŠ è½½æ¨¡å‹
let loaded_llm = load_model_binary("checkpoints/model_epoch_100.bin")?;
```

### 2. ä½¿ç”¨ JSON æ ¼å¼

```rust
use llm::{save_model_json, load_model_json};

// ä¿å­˜ä¸ºJSON(æ–¹ä¾¿è°ƒè¯•)
save_model_json(&llm, "exports/model_weights.json")?;

// ä»JSONåŠ è½½
let loaded_llm = load_model_json("exports/model_weights.json")?;
```

### 3. è‡ªåŠ¨æ ¼å¼è¯†åˆ«

```rust
use llm::load_model_auto;

// æ ¹æ®æ–‡ä»¶æ‰©å±•åè‡ªåŠ¨é€‰æ‹©æ ¼å¼
let llm = load_model_auto("checkpoints/model.bin")?;  // äºŒè¿›åˆ¶
let llm = load_model_auto("exports/model.json")?;     // JSON
```

## ğŸ’¡ å®Œæ•´è®­ç»ƒç¤ºä¾‹

```rust
use llm::{LLM, Vocab, save_model_binary, load_model_binary};
use std::collections::HashSet;

fn main() -> Result<(), Box<dyn std::error::Error>> {
    // 1. å‡†å¤‡è®­ç»ƒæ•°æ®
    let training_texts = vec![
        "ä¸­å›½æ˜¯ä¸€ä¸ªå†å²æ‚ ä¹…çš„å›½å®¶".to_string(),
        "äººå·¥æ™ºèƒ½æŠ€æœ¯æ­£åœ¨å¿«é€Ÿå‘å±•".to_string(),
        // ... æ›´å¤šè®­ç»ƒæ•°æ®
    ];

    // 2. æ„å»ºè¯æ±‡è¡¨
    let mut vocab_set = HashSet::new();
    Vocab::process_text_for_vocab(&training_texts, &mut vocab_set);
    let vocab_words: Vec<String> = vocab_set.into_iter().collect();
    let vocab = Vocab::new(vocab_words.iter().map(|s| s.as_str()).collect());

    // 3. åˆ›å»ºæ¨¡å‹
    let mut llm = LLM::new(vocab, /* network layers */);

    // 4. è®­ç»ƒæ¨¡å‹
    let epochs = 100;
    for epoch in 0..epochs {
        let training_refs: Vec<&str> = training_texts.iter().map(|s| s.as_str()).collect();
        llm.train(training_refs, 1, 0.001);

        // æ¯10ä¸ªepochä¿å­˜ä¸€æ¬¡checkpoint
        if (epoch + 1) % 10 == 0 {
            let checkpoint_path = format!("checkpoints/model_epoch_{}.bin", epoch + 1);
            save_model_binary(&llm, &checkpoint_path)?;
            println!("âœ“ å·²ä¿å­˜checkpoint: {}", checkpoint_path);
        }
    }

    // 5. ä¿å­˜æœ€ç»ˆæ¨¡å‹
    save_model_binary(&llm, "model_final.bin")?;
    println!("âœ“ è®­ç»ƒå®Œæˆ,æ¨¡å‹å·²ä¿å­˜!");

    Ok(())
}
```

## ğŸ”„ æ–­ç‚¹ç»­è®­ç¤ºä¾‹

```rust
use llm::{load_model_binary, save_model_binary};

fn continue_training() -> Result<(), Box<dyn std::error::Error>> {
    // 1. ä»checkpointåŠ è½½æ¨¡å‹
    println!("ğŸ“‚ åŠ è½½checkpoint...");
    let mut llm = load_model_binary("checkpoints/model_epoch_50.bin")?;

    // 2. ç»§ç»­è®­ç»ƒ
    println!("ğŸ”„ ç»§ç»­è®­ç»ƒ...");
    let training_data = vec!["æ–°çš„è®­ç»ƒæ•°æ®1", "æ–°çš„è®­ç»ƒæ•°æ®2"];
    llm.train(training_data, 50, 0.0005);  // ç»§ç»­è®­ç»ƒ50ä¸ªepoch

    // 3. ä¿å­˜æ–°çš„checkpoint
    save_model_binary(&llm, "checkpoints/model_epoch_100.bin")?;
    println!("âœ“ è®­ç»ƒå®Œæˆ!");

    Ok(())
}
```

## ğŸ“Š æ ¼å¼å¯¹æ¯”

| ç‰¹æ€§ | äºŒè¿›åˆ¶æ ¼å¼ (.bin) | JSONæ ¼å¼ (.json) |
|-----|------------------|------------------|
| æ–‡ä»¶å¤§å° | å° | å¤§(çº¦3-5å€) |
| åŠ è½½é€Ÿåº¦ | å¿« | è¾ƒæ…¢ |
| äººç±»å¯è¯» | âŒ | âœ… |
| è·¨è¯­è¨€ | âŒ | âœ… |
| ä¼˜åŒ–å™¨çŠ¶æ€ | âœ… | âœ… |
| é€‚ç”¨åœºæ™¯ | ç”Ÿäº§/è®­ç»ƒ | è°ƒè¯•/ç ”ç©¶ |

## ğŸ—‚ï¸ æ¨èçš„æ–‡ä»¶ç»„ç»‡ç»“æ„

```
your_project/
â”œâ”€â”€ checkpoints/          # è®­ç»ƒcheckpoint
â”‚   â”œâ”€â”€ model_epoch_10.bin
â”‚   â”œâ”€â”€ model_epoch_20.bin
â”‚   â””â”€â”€ ...
â”œâ”€â”€ exports/              # å¯¼å‡ºçš„æ¨¡å‹
â”‚   â”œâ”€â”€ model_v1.bin     # ç”Ÿäº§æ¨¡å‹
â”‚   â””â”€â”€ model_v1.json    # è°ƒè¯•ç”¨JSON
â””â”€â”€ final_models/         # æœ€ç»ˆå‘å¸ƒæ¨¡å‹
    â””â”€â”€ model_release.bin
```

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **æ–‡ä»¶å¤§å°**: æ¨¡å‹æ–‡ä»¶å¯èƒ½è¾ƒå¤§(å‡ MBåˆ°å‡ GB),ç¡®ä¿æœ‰è¶³å¤Ÿç£ç›˜ç©ºé—´

2. **ç‰ˆæœ¬å…¼å®¹æ€§**: å½“å‰æ ¼å¼ç‰ˆæœ¬ä¸ºv1,æœªæ¥ç‰ˆæœ¬å¯èƒ½ä¸å‘åå…¼å®¹

3. **å®‰å…¨æ€§**: æ¨¡å‹æ–‡ä»¶åŒ…å«å®Œæ•´ç½‘ç»œå‚æ•°,å¦¥å–„ä¿ç®¡é¿å…æ³„éœ²

4. **JSONç²¾åº¦**: JSONæ ¼å¼å¯èƒ½æœ‰å¾®å°çš„æµ®ç‚¹ç²¾åº¦æŸå¤±

5. **è·¯å¾„å¤„ç†**: å»ºè®®åˆ›å»ºç›®å½•åå†ä¿å­˜:
   ```rust
   std::fs::create_dir_all("checkpoints")?;
   save_model_binary(&llm, "checkpoints/model.bin")?;
   ```

## ğŸ› æ•…éšœæ’æŸ¥

### é—®é¢˜: åŠ è½½æ¨¡å‹å¤±è´¥

**å¯èƒ½åŸå› :**
- æ–‡ä»¶æŸå
- æ ¼å¼ç‰ˆæœ¬ä¸åŒ¹é…
- æ–‡ä»¶è·¯å¾„é”™è¯¯

**è§£å†³æ–¹æ³•:**
```rust
match load_model_binary("model.bin") {
    Ok(model) => println!("åŠ è½½æˆåŠŸ!"),
    Err(e) => eprintln!("åŠ è½½å¤±è´¥: {}", e),
}
```

### é—®é¢˜: æ–‡ä»¶è¿‡å¤§

**è§£å†³æ–¹æ³•:**
- ä½¿ç”¨äºŒè¿›åˆ¶æ ¼å¼è€ŒéJSON
- è€ƒè™‘æ¨¡å‹å‹ç¼©æŠ€æœ¯(å‰ªæã€é‡åŒ–)
- åªä¿å­˜å¿…è¦çš„checkpoint

## ğŸ“– ç›¸å…³APIæ–‡æ¡£

### ä¿å­˜å‡½æ•°

```rust
/// ä¿å­˜æ¨¡å‹åˆ°äºŒè¿›åˆ¶æ–‡ä»¶
pub fn save_model_binary<P: AsRef<Path>>(
    model: &LLM,
    path: P,
) -> Result<(), Box<dyn std::error::Error>>

/// ä¿å­˜æ¨¡å‹åˆ°JSONæ–‡ä»¶
pub fn save_model_json<P: AsRef<Path>>(
    model: &LLM,
    path: P,
) -> Result<(), Box<dyn std::error::Error>>
```

### åŠ è½½å‡½æ•°

```rust
/// ä»äºŒè¿›åˆ¶æ–‡ä»¶åŠ è½½æ¨¡å‹
pub fn load_model_binary<P: AsRef<Path>>(
    path: P,
) -> Result<LLM, Box<dyn std::error::Error>>

/// ä»JSONæ–‡ä»¶åŠ è½½æ¨¡å‹
pub fn load_model_json<P: AsRef<Path>>(
    path: P,
) -> Result<LLM, Box<dyn std::error::Error>>

/// è‡ªåŠ¨è¯†åˆ«æ ¼å¼å¹¶åŠ è½½
pub fn load_model_auto<P: AsRef<Path>>(
    path: P,
) -> Result<LLM, Box<dyn std::error::Error>>
```

## ğŸ¯ æœ€ä½³å®è·µ

1. **å®šæœŸä¿å­˜**: è®­ç»ƒè¿‡ç¨‹ä¸­å®šæœŸä¿å­˜checkpoint,é¿å…æ„å¤–ä¸­æ–­å¯¼è‡´æ•°æ®ä¸¢å¤±

2. **å‘½åè§„èŒƒ**: ä½¿ç”¨æè¿°æ€§çš„æ–‡ä»¶å,åŒ…å«epochæ•°ã€æ—¥æœŸç­‰ä¿¡æ¯

3. **å¤‡ä»½ç­–ç•¥**: ä¿ç•™å¤šä¸ªå†å²ç‰ˆæœ¬,é¿å…è¦†ç›–å”¯ä¸€çš„æ¨¡å‹æ–‡ä»¶

4. **æµ‹è¯•åŠ è½½**: ä¿å­˜åç«‹å³æµ‹è¯•åŠ è½½,ç¡®è®¤æ–‡ä»¶å®Œæ•´æ€§

5. **ç¯å¢ƒåŒºåˆ†**: å¼€å‘ç¯å¢ƒä½¿ç”¨JSONè°ƒè¯•,ç”Ÿäº§ç¯å¢ƒä½¿ç”¨äºŒè¿›åˆ¶æ ¼å¼

## ğŸ”¬ é«˜çº§ç”¨æ³•

### å¯¼å‡ºæƒé‡ç»™Pythonä½¿ç”¨

```rust
// å¯¼å‡ºä¸ºJSON
save_model_json(&llm, "model_for_python.json")?;
```

```python
# Pythonä»£ç è¯»å–
import json

with open("model_for_python.json", "r") as f:
    model_data = json.load(f)

# è®¿é—®æƒé‡
vocab = model_data["vocab"]
layers = model_data["layers"]
print(f"è¯æ±‡é‡: {len(vocab['words'])}")
```

---

**ç›¸å…³æ–‡æ¡£:**
- [CLAUDE.md](CLAUDE.md) - é¡¹ç›®æ¶æ„è¯´æ˜
- [README_zh.md](README_zh.md) - é¡¹ç›®ä»‹ç»
