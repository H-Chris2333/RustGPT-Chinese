// æ¨¡å‹ä¿å­˜å’ŒåŠ è½½ç¤ºä¾‹ç¨‹åº
//
// ä½¿ç”¨æ–¹æ³•:
// 1. è®­ç»ƒå¹¶ä¿å­˜: cargo run --bin save_model
// 2. åŠ è½½å¹¶ä½¿ç”¨: cargo run --bin load_model

use llm::{
    Dataset, EMBEDDING_DIM, Embeddings, HIDDEN_DIM, LLM, OutputProjection, TransformerBlock, Vocab,
    load_model_binary, save_model_binary,
};
use std::collections::HashSet;

fn main() -> Result<(), Box<dyn std::error::Error>> {
    // åˆå§‹åŒ–æ—¥å¿—
    if let Err(e) = simple_logger::SimpleLogger::new()
        .with_level(log::LevelFilter::Info)
        .init()
    {
        eprintln!("æ—¥å¿—åˆå§‹åŒ–å¤±è´¥: {}", e);
    }

    // æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
    let args: Vec<String> = std::env::args().collect();

    if args.len() > 1 {
        match args[1].as_str() {
            "save" => train_and_save()?,
            "load" => load_and_use()?,
            "continue" => continue_training()?,
            _ => print_usage(),
        }
    } else {
        print_usage();
    }

    Ok(())
}

fn print_usage() {
    println!(
        "
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘         RustGPT-Chinese æ¨¡å‹ä¿å­˜/åŠ è½½å·¥å…·                 â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ä½¿ç”¨æ–¹æ³•:
  cargo run --bin model_persistence save       # è®­ç»ƒå¹¶ä¿å­˜æ¨¡å‹
  cargo run --bin model_persistence load       # åŠ è½½å¹¶ä½¿ç”¨æ¨¡å‹
  cargo run --bin model_persistence continue   # ä»checkpointç»§ç»­è®­ç»ƒ

ç¤ºä¾‹:
  # è®­ç»ƒ100ä¸ªepochå¹¶ä¿å­˜
  cargo run --bin model_persistence save

  # åŠ è½½æ¨¡å‹å¹¶è¿›è¡Œå¯¹è¯
  cargo run --bin model_persistence load

  # ä»checkpointç»§ç»­è®­ç»ƒ50ä¸ªepoch
  cargo run --bin model_persistence continue
"
    );
}

/// è®­ç»ƒæ¨¡å‹å¹¶ä¿å­˜
fn train_and_save() -> Result<(), Box<dyn std::error::Error>> {
    println!("\nğŸš€ å¼€å§‹è®­ç»ƒæ¨¡å‹...\n");

    // 1. åŠ è½½æ•°æ®
    println!("ğŸ“‚ åŠ è½½è®­ç»ƒæ•°æ®...");
    let dataset = Dataset::new(
        String::from("data/pretraining_data.json"),
        String::from("data/chat_training_data.json"),
    );

    // 2. æ„å»ºè¯æ±‡è¡¨
    println!("ğŸ“ æ„å»ºè¯æ±‡è¡¨...");
    let mut vocab_set = HashSet::new();
    Vocab::process_text_for_vocab(&dataset.pretraining_data, &mut vocab_set);
    Vocab::process_text_for_vocab(&dataset.chat_training_data, &mut vocab_set);

    let mut vocab_words: Vec<String> = vocab_set.into_iter().collect();
    vocab_words.sort();
    let vocab_words_refs: Vec<&str> = vocab_words.iter().map(|s| s.as_str()).collect();
    let vocab = Vocab::new(vocab_words_refs);

    println!("âœ“ è¯æ±‡è¡¨åˆ›å»ºå®Œæˆ: {} ä¸ªè¯å…ƒ\n", vocab.len());

    // 3. åˆ›å»ºæ¨¡å‹
    println!("ğŸ—ï¸  åˆå§‹åŒ–æ¨¡å‹...");
    let transformer_block_1 = TransformerBlock::new(EMBEDDING_DIM, HIDDEN_DIM);
    let transformer_block_2 = TransformerBlock::new(EMBEDDING_DIM, HIDDEN_DIM);
    let transformer_block_3 = TransformerBlock::new(EMBEDDING_DIM, HIDDEN_DIM);
    let transformer_block_4 = TransformerBlock::new(EMBEDDING_DIM, HIDDEN_DIM);
    let output_projection = OutputProjection::new(EMBEDDING_DIM, vocab.words.len());
    let embeddings = Embeddings::new(vocab.clone());

    let mut llm = LLM::new(
        vocab,
        vec![
            Box::new(embeddings),
            Box::new(transformer_block_1),
            Box::new(transformer_block_2),
            Box::new(transformer_block_3),
            Box::new(transformer_block_4),
            Box::new(output_projection),
        ],
    );

    println!("âœ“ æ¨¡å‹åˆå§‹åŒ–å®Œæˆ");
    println!("  â€¢ æ€»å‚æ•°é‡: {}", llm.total_parameters());
    println!("  â€¢ ç½‘ç»œæ¶æ„: {}\n", llm.network_description());

    // 4. é¢„è®­ç»ƒ
    println!("ğŸ¯ é˜¶æ®µ1: é¢„è®­ç»ƒ (100 epochs, lr=0.0005)");
    let pretraining_examples: Vec<&str> = dataset
        .pretraining_data
        .iter()
        .map(|s| s.as_str())
        .collect();

    llm.train(pretraining_examples, 100, 0.0005);

    // ä¿å­˜checkpoint
    println!("\nğŸ’¾ ä¿å­˜é¢„è®­ç»ƒcheckpoint...");
    std::fs::create_dir_all("checkpoints")?;
    save_model_binary(&llm, "checkpoints/model_pretrained.bin")?;

    // 5. æŒ‡ä»¤å¾®è°ƒ
    println!("\nğŸ¯ é˜¶æ®µ2: æŒ‡ä»¤å¾®è°ƒ (100 epochs, lr=0.0001)");
    let chat_training_examples: Vec<&str> = dataset
        .chat_training_data
        .iter()
        .map(|s| s.as_str())
        .collect();

    llm.train(chat_training_examples, 100, 0.0001);

    // 6. ä¿å­˜æœ€ç»ˆæ¨¡å‹
    println!("\nğŸ’¾ ä¿å­˜æœ€ç»ˆæ¨¡å‹...");
    save_model_binary(&llm, "checkpoints/model_final.bin")?;

    println!("\nâœ… è®­ç»ƒå®Œæˆ!");
    println!("   æ¨¡å‹å·²ä¿å­˜åˆ°:");
    println!("   â€¢ checkpoints/model_pretrained.bin (é¢„è®­ç»ƒcheckpoint)");
    println!("   â€¢ checkpoints/model_final.bin (æœ€ç»ˆæ¨¡å‹)");
    println!("\nğŸ’¡ æç¤º: ä½¿ç”¨ 'cargo run --bin model_persistence load' åŠ è½½æ¨¡å‹\n");

    Ok(())
}

/// åŠ è½½æ¨¡å‹å¹¶ä½¿ç”¨
fn load_and_use() -> Result<(), Box<dyn std::error::Error>> {
    println!("\nğŸ“‚ åŠ è½½æ¨¡å‹...\n");

    // åŠ è½½æ¨¡å‹
    let mut llm = load_model_binary("checkpoints/model_final.bin")?;
    llm.set_training_mode(false);

    println!("\nâœ… æ¨¡å‹åŠ è½½æˆåŠŸ!");
    println!("   â€¢ è¯æ±‡é‡: {}", llm.vocab.len());
    println!("   â€¢ æ€»å‚æ•°: {}", llm.total_parameters());

    // æµ‹è¯•å¯¹è¯
    println!("\n--- è¿›å…¥äº¤äº’æ¨¡å¼ ---");
    println!("è¾“å…¥é—®é¢˜æŒ‰å›è½¦ç”Ÿæˆå›ç­”,è¾“å…¥ 'exit' é€€å‡º\n");

    let mut input = String::new();
    loop {
        input.clear();

        print!("ğŸ‘¤ ç”¨æˆ·: ");
        if let Err(e) = std::io::stdout().flush() {
            log::warn!("åˆ·æ–°æ ‡å‡†è¾“å‡ºå¤±è´¥: {}", e);
        }

        if let Err(e) = std::io::stdin().read_line(&mut input) {
            log::warn!("è¯»å–è¾“å…¥å¤±è´¥: {}", e);
            continue;
        }

        let trimmed_input = input.trim();
        if trimmed_input.eq_ignore_ascii_case("exit") {
            println!("ğŸ‘‹ å†è§!");
            break;
        }

        let formatted_input = format!("ç”¨æˆ·ï¼š{}", trimmed_input);
        print!("ğŸ¤– æ¨¡å‹: ");
        if let Err(e) = std::io::stdout().flush() {
            log::warn!("åˆ·æ–°æ ‡å‡†è¾“å‡ºå¤±è´¥: {}", e);
        }

        let prediction = llm.predict_with_beam_search(&formatted_input, 3, 20);
        println!("{}\n", prediction);

        // æ£€æµ‹åˆ°ç»“æŸç¬¦æ—¶æ¸…ç©ºä¸Šä¸‹æ–‡
        if prediction.contains("</s>") {
            llm.clear_context();
        }
    }

    Ok(())
}

/// ä»checkpointç»§ç»­è®­ç»ƒ
fn continue_training() -> Result<(), Box<dyn std::error::Error>> {
    println!("\nğŸ“‚ ä»checkpointç»§ç»­è®­ç»ƒ...\n");

    // 1. åŠ è½½checkpoint
    println!("åŠ è½½é¢„è®­ç»ƒcheckpoint...");
    let mut llm = load_model_binary("checkpoints/model_pretrained.bin")?;
    llm.set_training_mode(true);

    println!("âœ“ CheckpointåŠ è½½æˆåŠŸ\n");

    // 2. åŠ è½½æ•°æ®
    println!("ğŸ“‚ åŠ è½½è®­ç»ƒæ•°æ®...");
    let dataset = Dataset::new(
        String::from("data/pretraining_data.json"),
        String::from("data/chat_training_data.json"),
    );

    // 3. ç»§ç»­è®­ç»ƒ
    println!("\nğŸ¯ ç»§ç»­æŒ‡ä»¤å¾®è°ƒ (50 epochs, lr=0.0001)");
    let chat_training_examples: Vec<&str> = dataset
        .chat_training_data
        .iter()
        .map(|s| s.as_str())
        .collect();

    llm.train(chat_training_examples, 50, 0.0001);

    // 4. ä¿å­˜æ–°æ¨¡å‹
    println!("\nğŸ’¾ ä¿å­˜ç»§ç»­è®­ç»ƒåçš„æ¨¡å‹...");
    save_model_binary(&llm, "checkpoints/model_continued.bin")?;

    println!("\nâœ… ç»§ç»­è®­ç»ƒå®Œæˆ!");
    println!("   æ¨¡å‹å·²ä¿å­˜åˆ°: checkpoints/model_continued.bin\n");

    Ok(())
}

use std::io::Write;
